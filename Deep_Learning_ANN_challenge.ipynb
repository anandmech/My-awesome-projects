{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning_ANN challenge.ipynb",
      "provenance": [],
      "mount_file_id": "1SWTXBVcZanmdz2sZsdNAzZzb0aVauFVO",
      "authorship_tag": "ABX9TyOyjwigKnJlDpsYylzm9qFc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl9TAIXAqm0S"
      },
      "source": [
        "###Artificial Neural Network (ANN) Challenge\r\n",
        "####In this challenge, I'll work with dataset: fashion MNIST. Using this dataset, I'll do the following:\r\n",
        "\r\n",
        "####1.Preprocess your data so that you can feed it into ANN models.\r\n",
        "\r\n",
        "####2.Split your data into training and test sets.\r\n",
        "\r\n",
        "####3.Try different ANN models and train them on your training set. \r\n",
        "\r\n",
        "#####1.Number of layers\r\n",
        "#####2.Activation functions of the layers\r\n",
        "#####3.Number of neurons in the layers\r\n",
        "#####4.Different batch sizes during training\r\n",
        "\r\n",
        "####4.Compare your models' training scores and interpret your results.\r\n",
        "\r\n",
        "####4.Evaluate how your models perform on your test set. Compare the results of your models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqEs3aERrRLy"
      },
      "source": [
        "#####Use GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzQ9j3WRqZOl",
        "outputId": "23e1247d-0c35-441f-c0c0-c12211f984e7"
      },
      "source": [
        "pip install tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.19.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/keras-applications/\u001b[0m\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.12.4)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-rc1) (51.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c30WnMwDrZxH"
      },
      "source": [
        "#####Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQy3rPW6rAEa"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.models import Sequential \r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2R2igE2riO5"
      },
      "source": [
        "#####1.Preprocess your data so that you can feed it into ANN models.\r\n",
        "#####2. Split your data into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhGe03B2rdyy",
        "outputId": "f166cada-fcb9-4826-a7d4-925d03cbfe25"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "#Fashion MNIST has 28x28 greyscale images, so 28x28 = 784\r\n",
        "input_dim = 784  \r\n",
        "output_dim = nb_classes = 10\r\n",
        "nb_epoch = 20\r\n",
        "\r\n",
        "#Split into test and training sets\r\n",
        "X_train = X_train.reshape(60000, input_dim)\r\n",
        "X_test = X_test.reshape(10000, input_dim)\r\n",
        "\r\n",
        "#Convert to float type\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "\r\n",
        "#Normalize the vectors\r\n",
        "X_train /= 255\r\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vqKkws8s7vh"
      },
      "source": [
        "#####Convert categorical to numerical variables with one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlN0Ahmls2m9"
      },
      "source": [
        "Y_train = to_categorical(y_train, nb_classes)\r\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DA56xT7tEOt"
      },
      "source": [
        "#####3. Try different ANN models and train them on your training set. You can play with the following:\r\n",
        "\r\n",
        "######1.Number of layers\r\n",
        "######2.Activation functions of the layers\r\n",
        "######3.Number of neurons in the layers\r\n",
        "######4.Different batch sizes during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWGBRXBQtV8t"
      },
      "source": [
        "#####Let's start with 3 dense layers with 128, 64, and 10 neurons, with batch size set to 128 as a starting point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULx0aoyptBkZ",
        "outputId": "095aaab4-0c74-4b2f-83a4-98f052b23450"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359ddba7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359ddba7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Test score: 0.42172230417728424\n",
            "Test accuracy: 0.8507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDAG9dq1t3ci"
      },
      "source": [
        "#####The model had a decent accuracy score of 0.85. But it suffers from overfitting. Let's add another layer and see how they compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbB9C4F6tolk",
        "outputId": "f83e593f-2031-4308-95d2-a571c871b174"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 4 dense layers with 128, 64, 58, 10 neurons\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(58, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359a79fea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359a79fea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Test score: 0.39879621031284335\n",
            "Test accuracy: 0.8576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59lxq2TAuQ4u"
      },
      "source": [
        "#####The results are very similar. Let's add another layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok-mjpSLuFrr",
        "outputId": "54f6b902-a639-457e-ccce-d17f7c00bbdc"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 5 dense layers with 128, 100, 64, 58, 10 neurons\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(100, activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(58, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359903d6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359903d6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Test score: 0.4018573496341705\n",
            "Test accuracy: 0.8546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJrpUf14uuC2"
      },
      "source": [
        "#####Adding another layer increased the test score's accuracy but the training score lowered.Let's stick to 3 layers and and try sigmoid, tanh, and ReLU activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B650Wk5wvCf3"
      },
      "source": [
        "#####Using Sigmoid function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgOcISTgubco",
        "outputId": "b4e9a165-0471-4361-cd47-16fcba4dbf02"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons with activation set to sigmoid\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359cbe72f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359cbe72f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Test score: 0.4967690366268158\n",
            "Test accuracy: 0.8219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvP6IjigvLib"
      },
      "source": [
        "#####Using tanh function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvRmfvkcvB7f",
        "outputId": "f4d690be-b8c9-43fc-e6c6-550ceb82f95c"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons with activation set to tanh\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f35a4bc8ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f35a4bc8ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Test score: 0.41139678983688355\n",
            "Test accuracy: 0.8533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icb3AOrMvVgx"
      },
      "source": [
        "Using ReLU function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVzZbOSDvQON",
        "outputId": "cb04b588-7bf6-4fd2-ee4b-bfe4803b5cd0"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons with activation set to 'relu'\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359bdf3268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f359bdf3268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Test score: 0.4226639069080353\n",
            "Test accuracy: 0.8509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mprth5KvlY8"
      },
      "source": [
        "#####The model that used the ReLU activation function had a slightly higher accuracy score for the test set than the one that used the tanh activation function.The ReLU and tanh models also had very similar scores for the training sets. The model with the sigmoid activation function had a lower accuracy score for the test set but a higher accuracy score for the training set. But none of the three models appear to suffer from overfitting. The model that used the ReLU activation function did perform the best "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHzCdiXEdqz7"
      },
      "source": [
        "#####Now let's vary the number of neurons in each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzb_26kyvYbi",
        "outputId": "6e06c683-7f36-4656-b355-f7a0f9212343"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons with ReLU activation\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.4196259379386902\n",
            "Test accuracy: 0.8514000177383423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHqE14eVeDpH",
        "outputId": "2794a7e2-f8c4-4f42-8e65-484c3843d24e"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 100, 50, 10 neurons with ReLU activation\r\n",
        "model.add(Dense(100, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(50, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.41667118668556213\n",
            "Test accuracy: 0.8537999987602234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMywAJoBeEW-",
        "outputId": "75010982-2893-412d-c208-f6cd5139d8df"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 1000, 500, 10 neurons with ReLU activation\r\n",
        "model.add(Dense(1000, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(500, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.4107329547405243\n",
            "Test accuracy: 0.852400004863739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGUP4x_HeZno",
        "outputId": "985fbba7-9631-4fc0-a108-7da6dd3bc127"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 2000, 1000, 10 neurons with activation set to 'relu'\r\n",
        "model.add(Dense(1500, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(800, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.40162894129753113\n",
            "Test accuracy: 0.8557999730110168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY0HNctBfClJ"
      },
      "source": [
        "##### I achieved a slightly higher accuracy when changing the number of neurons in the layers.The models took longer to run with 1000, 500, 10 neurons and 2000, 1000, 10 neurons. So it's not worth the compuational power needed to achieve slightly higher accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G96_2yyafopt"
      },
      "source": [
        "##### Finally let's try with different batch sizes in training with higher, lower and full batch sizes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22iiHCsDfkfu",
        "outputId": "21d56a54-440d-447b-a169-be462965697d"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons with activation set to 'relu'\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 128 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.4197782278060913\n",
            "Test accuracy: 0.8528000116348267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bA7vS7ogB99",
        "outputId": "95352221-2da5-42e5-9727-e8ba06b48bd6"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons with activation set to 'relu'\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#set 8 as mini batch size\r\n",
        "model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.3273168206214905\n",
            "Test accuracy: 0.8871999979019165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9TW8tf5gQUj",
        "outputId": "31c852bd-da07-414e-b8b0-d8b401749d7f"
      },
      "source": [
        "#build the model\r\n",
        "model = Sequential()\r\n",
        "# add 3 dense layers with 128, 64, 10 neurons with activation set to 'relu'\r\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\r\n",
        "model.add(Dense(64, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "#compile the model\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "#use full sample\r\n",
        "model.fit(X_train, Y_train, batch_size=X_train.shape[0], epochs=20, verbose=False)\r\n",
        "#evaluate the model\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test score:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 2.0586607456207275\n",
            "Test accuracy: 0.296099990606308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yXJJeZhh7QZ"
      },
      "source": [
        "#####Varying the batch size yielded interesting results. Using the full batch size gave the lowest accuracy of 30%. Using a higher batch size of 128 yielded accuracy of 85% on test set and a 42% accuracy on the training set. Using a lower batch size of 8 yielded highest accuracy of 89% on test set and only 33% accuracy on training set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_crq_jJj9Gh"
      },
      "source": [
        "#####Based on a comparison of all the model results, the model with 3 dense layers, with 128, 64, and 10 neurons, with batch size set to 128, and with the ReLU activation function performed the best. This model also suffers least from overfitting based on the difference between the test and training set accuracy scores. The training accuracy is 85% is reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UZJGlKykiX_"
      },
      "source": [
        "#####For future work, I can look at using diffrent hyper parameters and try to achieve even higher accuracy scores. I can also look at trying a different Deep learning approach to see if we can improve the accuracy scores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7_3SfxujEkB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}